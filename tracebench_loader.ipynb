{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Dict, Optional, List\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_read_csv(path):\n",
    "    \"\"\"Fix event.csv dynamically by quoting the Description field if missing.\"\"\"\n",
    "    fixed_lines = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        header = f.readline().strip()\n",
    "        fixed_lines.append(header)\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\n')\n",
    "            # Split only the first 8 commas: 9 columns total\n",
    "            parts = line.split(',', 8)\n",
    "            if len(parts) == 9:\n",
    "                # If the last field (Description) contains commas but is unquoted, wrap it\n",
    "                desc = parts[-1]\n",
    "                if not desc.startswith('\"') and ',' in desc:\n",
    "                    parts[-1] = f'\"{desc}\"'\n",
    "                fixed_lines.append(','.join(parts))\n",
    "\n",
    "    # Now read the corrected lines with pandas\n",
    "    from io import StringIO\n",
    "    buffer = StringIO('\\n'.join(fixed_lines))\n",
    "    df = pd.read_csv(buffer)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_structure_from_folder(dirname):\n",
    "    _ABN_PREFIX = re.compile(r\"^(AN|NM)_\", re.IGNORECASE)\n",
    "    d = dirname.strip('/')\n",
    "    m = _ABN_PREFIX.match(d)\n",
    "    if not m:\n",
    "        # Fallback for COM\n",
    "        return {\n",
    "            'is_abnormal': None,\n",
    "            'class_label': None,\n",
    "            'category': None,\n",
    "            'fault_type': None,\n",
    "            'workload': None,\n",
    "            'variables': None,\n",
    "        }\n",
    "\n",
    "    # Label\n",
    "    is_abn = (m.group(1).upper() == 'AN')\n",
    "    parts = d.split('_')\n",
    "\n",
    "    # Category + Fault Type\n",
    "    category = None\n",
    "    fault = None\n",
    "\n",
    "    if is_abn:\n",
    "        if len(parts) >= 3:\n",
    "            category = parts[1]\n",
    "            fault = parts[2]\n",
    "        start_idx = 3\n",
    "    else:\n",
    "        if len(parts) >= 2:\n",
    "            category = parts[1]\n",
    "        start_idx = 2\n",
    "\n",
    "    # Workload + Variables\n",
    "    allowed_workloads = {'r', 'w', 'rw', 'rpc', 'rwrpc'}\n",
    "    for i in range(start_idx, len(parts)):\n",
    "        tok = parts[i].lower()\n",
    "        if tok in allowed_workloads:\n",
    "            workload = tok\n",
    "            if i + 1 < len(parts):\n",
    "                # Keep the rest\n",
    "                variables = '_'.join(parts[i+1:])\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        'is_abnormal': int(is_abn),\n",
    "        'class_label': 'Abnormal' if is_abn else 'Normal',\n",
    "        'category': category,\n",
    "        'fault_type': fault,\n",
    "        'workload': workload,\n",
    "        'variables': variables,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TraceSet:\n",
    "    name: str\n",
    "    dirpath: str\n",
    "    labels: Dict[str, Optional[str]]\n",
    "    trace: pd.DataFrame\n",
    "    event: pd.DataFrame\n",
    "    edge: pd.DataFrame\n",
    "    operation: pd.DataFrame\n",
    "\n",
    "\n",
    "def load_trace_set(dirpath):\n",
    "    name = os.path.basename(os.path.normpath(dirpath))\n",
    "    labels = extract_structure_from_folder(name)\n",
    "\n",
    "    try:\n",
    "        print(f\"Loading: {name}\")\n",
    "\n",
    "        trace = pd.read_csv(os.path.join(dirpath, \"trace.csv\"))\n",
    "        event = fixed_read_csv(os.path.join(dirpath, \"event.csv\"))\n",
    "        edge = pd.read_csv(os.path.join(dirpath, \"edge.csv\"))\n",
    "        operation = pd.read_csv(os.path.join(dirpath, \"operation.csv\"))\n",
    "\n",
    "        return TraceSet(name, dirpath, labels, trace, event, edge, operation)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading files in folder: {dirpath}\")\n",
    "        print(f\"Error message: {type(e).__name__}: {e}\")\n",
    "        raise\n",
    "\n",
    "def iter_trace_sets(root):\n",
    "    required = {\"trace.csv\", \"event.csv\", \"edge.csv\", \"operation.csv\"}\n",
    "    valid_dirs = []\n",
    "\n",
    "    for name in sorted(os.listdir(root)):\n",
    "        folder = os.path.join(root, name)\n",
    "        if not os.path.isdir(folder):\n",
    "            continue\n",
    "        files = set(os.listdir(folder))\n",
    "        if required.issubset(files):\n",
    "            valid_dirs.append(folder)\n",
    "\n",
    "    return valid_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_master_tables(sets):\n",
    "    traces, events, edges, ops = [], [], [], []\n",
    "\n",
    "    for ts in sets:\n",
    "        labels = ts.labels or {}\n",
    "        meta = {\n",
    "            # \"SetName\":    ts.name,\n",
    "            \"Label\": labels.get(\"class_label\"),\n",
    "            \"IsAbnormal\": labels.get(\"is_abnormal\"),\n",
    "            \"FaultType\":  labels.get(\"fault_type\"),\n",
    "            \"Category\":    labels.get(\"category\"),\n",
    "            \"Workload\":    labels.get(\"workload\"),\n",
    "            \"Variables\":   labels.get(\"variables\"),\n",
    "        }\n",
    "        traces.append(ts.trace.assign(**meta))\n",
    "        events.append(ts.event)\n",
    "        edges.append(ts.edge)\n",
    "        ops.append(ts.operation)\n",
    "\n",
    "    traces_df = pd.concat(traces, ignore_index=True)\n",
    "    events_df = pd.concat(events, ignore_index=True)\n",
    "    edges_df  = pd.concat(edges,  ignore_index=True)\n",
    "    ops_df    = pd.concat(ops,    ignore_index=True)\n",
    "    \n",
    "    return traces_df, events_df, edges_df, ops_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tracebench(root_dir):\n",
    "    # Load all trace sets\n",
    "    # sets = [load_trace_set(p) for p in iter_trace_sets(root_dir)]\n",
    "    all_dirs = iter_trace_sets(root_dir)\n",
    "    sample_dirs = all_dirs[:1]\n",
    "    sets = [load_trace_set(p) for p in sample_dirs]\n",
    "    print(f\"Loaded {len(sets)} trace sets from {root_dir}\")\n",
    "\n",
    "    traces_df, events_df, edges_df, ops_df = build_master_tables(sets)\n",
    "    print(f\"Loaded {len(sets)} sets from {root_dir}\")\n",
    "    print(f\"traces_df:   {traces_df.shape}\")\n",
    "    print(f\"events_df:   {events_df.shape}\")\n",
    "    print(f\"edges_df:    {edges_df.shape}\")\n",
    "    print(f\"ops_df:      {ops_df.shape}\")\n",
    "    \n",
    "    return traces_df, events_df, edges_df, ops_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: AN_Data_corruptBlk_r_00FDN_30C_1to19B_0to120INT_15RT_5WT\n",
      "Loaded 1 trace sets from tracebench\n",
      "Loaded 1 sets from tracebench\n",
      "traces_df:   (345, 14)\n",
      "events_df:   (41956, 9)\n",
      "edges_df:    (16333, 4)\n",
      "ops_df:      (15, 5)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"tracebench\"\n",
    "traces_df, events_df, edges_df, ops_df = load_tracebench(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder_sequences(events_df, traces_df, join_cols=(\"OpName\",\"Description\"), order_cols=(\"StartTime\",\"TID\")):\n",
    "    # Act on event_df\n",
    "    df = events_df.copy()\n",
    "\n",
    "    # Sort by TaskID then StartTime then TID (Order events in Trace)\n",
    "    if order_cols: df = df.sort_values([\"TaskID\"] + list(order_cols))\n",
    "\n",
    "    # Create events text column = content of join_cols\n",
    "    def get_events_text(row): return \" : \".join(str(row[c]) for c in join_cols if c in row and pd.notna(row[c]))\n",
    "    df[\"EventText\"] = df.apply(get_events_text, axis=1)\n",
    "\n",
    "    # Group by TaskID and aggregate text\n",
    "    seq = df.groupby(\"TaskID\")[\"EventText\"].apply(lambda s: \" \".join([t for t in s if t])).reset_index()\n",
    "\n",
    "    # Merge labels and info from traces_df\n",
    "    labels = traces_df[[\"TaskID\",\"IsAbnormal\",\"FaultType\",\"Category\"]]\n",
    "    return seq.merge(labels, on=\"TaskID\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TaskID</th>\n",
       "      <th>EventText</th>\n",
       "      <th>IsAbnormal</th>\n",
       "      <th>FaultType</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001A5EDF7557AA6D</td>\n",
       "      <td>readBlock : Success: OP: new blockSender : Suc...</td>\n",
       "      <td>1</td>\n",
       "      <td>corruptBlk</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0115DB0FAF9DE3D7</td>\n",
       "      <td>readBlock : Success: OP: new blockSender : Suc...</td>\n",
       "      <td>1</td>\n",
       "      <td>corruptBlk</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01B83468FCC96050</td>\n",
       "      <td>readBlock : Success: OP: new blockSender : Suc...</td>\n",
       "      <td>1</td>\n",
       "      <td>corruptBlk</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02FC208FFB86B49E</td>\n",
       "      <td>readBlock : Success: OP: new blockSender : Suc...</td>\n",
       "      <td>1</td>\n",
       "      <td>corruptBlk</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0316D92944BC018F</td>\n",
       "      <td>readBlock : Success: OP: new blockSender : Suc...</td>\n",
       "      <td>1</td>\n",
       "      <td>corruptBlk</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>FD5C1F2E617BB729</td>\n",
       "      <td>readBlock : Success: OP: new blockSender : Suc...</td>\n",
       "      <td>1</td>\n",
       "      <td>corruptBlk</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>FD9BE359BE18DD43</td>\n",
       "      <td>OP: new blockSender : Success: return(OP_STATU...</td>\n",
       "      <td>1</td>\n",
       "      <td>corruptBlk</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>FDD88D0C938A0617</td>\n",
       "      <td>readBlock : Success: OP: new blockSender : Suc...</td>\n",
       "      <td>1</td>\n",
       "      <td>corruptBlk</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>FEAD05403D9BE520</td>\n",
       "      <td>readBlock : Success: OP: new blockSender : Suc...</td>\n",
       "      <td>1</td>\n",
       "      <td>corruptBlk</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>FFCC2E5F753BBDEE</td>\n",
       "      <td>readBlock : Success: OP: new blockSender : Suc...</td>\n",
       "      <td>1</td>\n",
       "      <td>corruptBlk</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               TaskID                                          EventText  \\\n",
       "0    001A5EDF7557AA6D  readBlock : Success: OP: new blockSender : Suc...   \n",
       "1    0115DB0FAF9DE3D7  readBlock : Success: OP: new blockSender : Suc...   \n",
       "2    01B83468FCC96050  readBlock : Success: OP: new blockSender : Suc...   \n",
       "3    02FC208FFB86B49E  readBlock : Success: OP: new blockSender : Suc...   \n",
       "4    0316D92944BC018F  readBlock : Success: OP: new blockSender : Suc...   \n",
       "..                ...                                                ...   \n",
       "340  FD5C1F2E617BB729  readBlock : Success: OP: new blockSender : Suc...   \n",
       "341  FD9BE359BE18DD43  OP: new blockSender : Success: return(OP_STATU...   \n",
       "342  FDD88D0C938A0617  readBlock : Success: OP: new blockSender : Suc...   \n",
       "343  FEAD05403D9BE520  readBlock : Success: OP: new blockSender : Suc...   \n",
       "344  FFCC2E5F753BBDEE  readBlock : Success: OP: new blockSender : Suc...   \n",
       "\n",
       "     IsAbnormal   FaultType Category  \n",
       "0             1  corruptBlk     Data  \n",
       "1             1  corruptBlk     Data  \n",
       "2             1  corruptBlk     Data  \n",
       "3             1  corruptBlk     Data  \n",
       "4             1  corruptBlk     Data  \n",
       "..          ...         ...      ...  \n",
       "340           1  corruptBlk     Data  \n",
       "341           1  corruptBlk     Data  \n",
       "342           1  corruptBlk     Data  \n",
       "343           1  corruptBlk     Data  \n",
       "344           1  corruptBlk     Data  \n",
       "\n",
       "[345 rows x 5 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_encoder_sequences(events_df, traces_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_graph_data_for_trace(events_df, edges_df, traces_df, task_id, opname_to_ix=None):\n",
    "    # Get related lines in dfs\n",
    "    ev = events_df[events_df[\"TaskID\"]==task_id].copy()\n",
    "    ed = edges_df[edges_df[\"TaskID\"]==task_id].copy()\n",
    "    tr = traces_df[traces_df[\"TaskID\"]==task_id].iloc[0]\n",
    "\n",
    "    # print(ev.head())\n",
    "    # print(ed.head())\n",
    "    # print(tr)   \n",
    "\n",
    "    # Get all events in this trace\n",
    "    tids = ev[\"TID\"].astype(str).tolist()\n",
    "\n",
    "    # Assign index to each event\n",
    "    idx = {t:i for i,t in enumerate(tids)}\n",
    "\n",
    "    # Node features : X [N, F]\n",
    "    # Edge index : [2, E]\n",
    "    # Labels : y [1]\n",
    "\n",
    "    # Node features : normalized start time, normalized duration, in-degree, out-degree\n",
    "    st = ev[\"StartTime\"].astype(\"int64\")\n",
    "    et = ev[\"EndTime\"].astype(\"int64\")\n",
    "    dur = (et-st).clip(lower=0)\n",
    "    # Start time normalized\n",
    "    stn = (st - st.min()) / max(1, (st.max()-st.min()))\n",
    "    # Duration normalized\n",
    "    dun = dur / max(1, dur.max())\n",
    "\n",
    "    # Compute in-degree and out-degree\n",
    "    indeg = pd.Series(0, index=tids)\n",
    "    outdeg = pd.Series(0, index=tids)\n",
    "    for _, r in ed.iterrows():\n",
    "        # Count connections\n",
    "        if r[\"FatherTID\"] in idx: outdeg[r[\"FatherTID\"]] += 1\n",
    "        if r[\"ChildTID\"]  in idx: indeg[r[\"ChildTID\"]]  += 1\n",
    "\n",
    "    indeg_d  = indeg.to_dict()\n",
    "    outdeg_d = outdeg.to_dict()\n",
    "\n",
    "    # Final X\n",
    "    x_num = np.c_[stn.to_numpy(), dun.to_numpy(),\n",
    "                  ev[\"TID\"].map(indeg_d).fillna(0).to_numpy(),\n",
    "                  ev[\"TID\"].map(outdeg_d).fillna(0).to_numpy()]\n",
    "\n",
    "    # Categorical features\n",
    "    op_ix   = ev[\"OpName\"].map(lambda s: opname_to_ix.get(str(s),0)).to_numpy()\n",
    "\n",
    "    # Edges index\n",
    "    src, dst = [], []\n",
    "    for _, r in ed.iterrows():\n",
    "        u, v = r[\"FatherTID\"], r[\"ChildTID\"] # extract edges\n",
    "        if u in idx and v in idx: src.append(idx[u]); dst.append(idx[v]) # map to index\n",
    "\n",
    "    data = {\n",
    "        \"x_num\": x_num.astype(\"float32\"),\n",
    "        \"op_idx\": op_ix.astype(\"int64\"),\n",
    "        \"edge_index\": np.array([src, dst], dtype=\"int64\"),\n",
    "        \"y\": np.array([int(tr[\"IsAbnormal\"])], dtype=\"int64\"),\n",
    "        \"TraceId\": task_id,\n",
    "    }\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_num': array([[8.85373890e-01, 1.45931743e-04, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.83832335e-01, 1.54308102e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.85373890e-01, 7.53127752e-05, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.83832335e-01, 3.07711278e-04, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.85373890e-01, 4.33512650e-05, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.83832335e-01, 2.68570089e-04, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.85373890e-01, 4.58323666e-05, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.83832335e-01, 2.07043078e-04, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.85373890e-01, 2.25549957e-04, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.83832335e-01, 1.32118829e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832335e-01, 5.62620698e-06, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832335e-01, 7.36375951e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [7.06551657e-12, 9.26592504e-04, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83832335e-01, 1.60164032e-02, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832335e-01, 1.67393088e-02, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832335e-01, 1.69830583e-02, 1.00000000e+00, 2.60000000e+01],\n",
       "        [2.38825915e-09, 2.14777306e-01, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83832335e-01, 2.14536443e-01, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.83832633e-01, 7.41934491e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832633e-01, 3.16894989e-06, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832633e-01, 4.24743812e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [2.71866128e-07, 3.69382091e-04, 1.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 2.17830762e-01, 2.00000000e+00, 1.00000000e+00],\n",
       "        [3.37775111e-01, 1.29559179e-04, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83832633e-01, 2.29176832e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832633e-01, 2.62548937e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832633e-01, 2.73340498e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [3.37775111e-01, 1.96459800e-01, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83832633e-01, 1.96358711e-01, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.83832872e-01, 5.30372308e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832872e-01, 3.07529103e-06, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832872e-01, 4.35294278e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [3.37775379e-01, 1.51094035e-04, 1.00000000e+00, 0.00000000e+00],\n",
       "        [3.37775111e-01, 1.98134169e-01, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83832872e-01, 1.46002518e-02, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832872e-01, 1.48488535e-02, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832872e-01, 1.49230910e-02, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.85241777e-02, 8.29760742e-04, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.85241851e-02, 1.10188328e-01, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83832872e-01, 1.13421746e-01, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.83832991e-01, 4.95190143e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832991e-01, 4.61827767e-06, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832991e-01, 4.15404647e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.85243267e-02, 3.19510757e-04, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.85241777e-02, 1.15760349e-01, 2.00000000e+00, 1.00000000e+00],\n",
       "        [1.03013277e-01, 3.85415886e-04, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83832991e-01, 3.89009365e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832991e-01, 4.12453059e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832991e-01, 4.19821450e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [1.03013277e-01, 1.08666062e-01, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83832991e-01, 1.11702405e-01, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.83833170e-01, 5.30385660e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83833170e-01, 3.26070131e-06, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83833170e-01, 3.89180168e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [1.03013419e-01, 3.10475065e-04, 1.00000000e+00, 0.00000000e+00],\n",
       "        [1.03013277e-01, 1.14218235e-01, 2.00000000e+00, 1.00000000e+00],\n",
       "        [4.53160793e-01, 9.81598132e-05, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83833170e-01, 7.81256531e-04, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83833170e-01, 1.05330604e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83833170e-01, 1.12240133e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [4.53160793e-01, 1.05533414e-01, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83833170e-01, 1.09839380e-01, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.83833289e-01, 5.05595635e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83833289e-01, 3.14949330e-06, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83833289e-01, 4.64910299e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [4.53160942e-01, 4.04693965e-05, 1.00000000e+00, 0.00000000e+00],\n",
       "        [4.53160793e-01, 1.10296600e-01, 2.00000000e+00, 1.00000000e+00],\n",
       "        [9.99999881e-01, 1.20386903e-04, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83833289e-01, 1.91423844e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83833289e-01, 2.22800486e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83833289e-01, 2.30348716e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [9.99999881e-01, 1.10677414e-01, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83833289e-01, 1.17554039e-01, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.83833468e-01, 4.94730448e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83833468e-01, 3.25917517e-06, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83833468e-01, 4.34731555e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [1.00000000e+00, 1.43487647e-04, 1.00000000e+00, 0.00000000e+00],\n",
       "        [9.99999881e-01, 1.18913561e-01, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83920789e-01, 2.06966593e-04, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83833468e-01, 2.59969803e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83833468e-01, 2.72176950e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83833468e-01, 2.79549765e-03, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83920789e-01, 8.19038525e-02, 2.00000000e+00, 1.00000000e+00],\n",
       "        [8.83833468e-01, 8.25359970e-02, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.83833528e-01, 4.87096586e-05, 1.00000000e+00, 2.60000000e+01],\n",
       "        [8.83832335e-01, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
       "        [8.83920848e-01, 1.80839023e-04, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.83920789e-01, 8.41019005e-02, 2.00000000e+00, 1.00000000e+00]],\n",
       "       dtype=float32),\n",
       " 'op_idx': array([12,  5, 12,  5, 12,  5, 12,  5, 11,  4,  6,  9,  1, 13,  3,  7, 15,\n",
       "         2,  8,  6,  9, 16, 14,  1, 13,  3,  7, 15,  2,  8,  6,  9, 16, 14,\n",
       "        13,  3,  7,  1, 15,  2,  8,  6,  9, 16, 14,  1, 13,  3,  7, 15,  2,\n",
       "         8,  6,  9, 16, 14,  1, 13,  3,  7, 15,  2,  8,  6,  9, 16, 14,  1,\n",
       "        13,  3,  7, 15,  2,  8,  6,  9, 16, 14,  1, 13,  3,  7, 15,  2,  8,\n",
       "        10, 16, 14], dtype=int64),\n",
       " 'edge_index': array([[84, 85, 84, 84, 84, 84, 84, 22, 84, 84, 84, 33, 84, 84, 84, 44,\n",
       "         84, 84, 84, 55, 84, 84, 84, 66, 84, 84, 84, 77, 84, 84, 84, 87,\n",
       "         84, 84],\n",
       "        [ 0, 84,  2,  4,  6,  8, 22, 17, 21, 22, 33, 28, 32, 33, 44, 39,\n",
       "         43, 44, 55, 50, 54, 55, 66, 61, 65, 66, 77, 72, 76, 77, 87, 83,\n",
       "         86, 87]], dtype=int64),\n",
       " 'y': array([1], dtype=int64),\n",
       " 'TraceId': 'B076E6516B275ABB'}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_ops = sorted(events_df[\"OpName\"].astype(str).unique())\n",
    "opname_to_ix = {op: i+1 for i, op in enumerate(unique_ops)}\n",
    "opname_to_ix[\"<UNK>\"] = 0   # reserve 0 for unknown ops\n",
    "\n",
    "build_graph_data_for_trace(events_df, edges_df, traces_df, \"B076E6516B275ABB\", opname_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
